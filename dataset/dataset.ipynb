{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from random import choices\n",
    "import pandas as pd\n",
    "from dataset_helpers import *\n",
    "import os\n",
    "import torch\n",
    "save_path = os.getcwd() + '/output/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.getcwd() + '/houses/training_data.pkl','rb') as f:\n",
    "    training_data = pickle.load(f)\n",
    "    \n",
    "with open(os.getcwd() + '/houses/validation_data.pkl','rb') as f:\n",
    "    validation_data = pickle.load(f)\n",
    "\n",
    "data = []\n",
    "for i in range(len(training_data)):\n",
    "    data.append((training_data[i][1], training_data[i][2]))\n",
    "for i in range(len(validation_data)):\n",
    "    data.append((validation_data[i][1], validation_data[i][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[8 8 0]\n",
      "  [0 0 0]\n",
      "  [0 0 1]]]\n",
      "['nothing', 'wall', 'none', 'windows', 'windows', 'windows', 'windows', 'windows', 'roof']\n"
     ]
    }
   ],
   "source": [
    "# testing the annotation reversal\n",
    "a = [[[1,1,2], [3,4,5], [6,7,8]]]\n",
    "b = ['nothing', 'roof', 'windows', 'windows', 'windows', 'windows', 'windows', 'none', 'wall' ]\n",
    "\n",
    "reversed_annotation = b[1:] # exclude 'nothing' from re-indexing\n",
    "reversed_annotation.reverse()\n",
    "resorted_annotation = ['nothing']\n",
    "resorted_annotation += reversed_annotation\n",
    "\n",
    "print(clean_segmentation(np.array(a), b))\n",
    "print(resorted_annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structures = []\n",
    "for (segmentation, annotation) in data:\n",
    "    structure = clean_segmentation(segmentation, annotation)\n",
    "    reversed_annotation = annotation[1:] # exclude 'nothing' tag from reversal\n",
    "    reversed_annotation.reverse()\n",
    "    resorted_annotation = ['nothing']\n",
    "    resorted_annotation += reversed_annotation\n",
    "    structures.append((structure, resorted_annotation))\n",
    "    for n in range(1, 4):\n",
    "        structures.append((np.rot90(structure, k=n, axes=(0, 2)), resorted_annotation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(save_path + 'structures.pkl', 'wb') as f:\n",
    "    pickle.dump(structures, f, protocol=pickle.DEFAULT_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markov Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(save_path + 'structures.pkl','rb') as f:\n",
    "    structures = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_table, segments_dict = calculate_markov_transitions(structures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(save_path + 'transition_table.pkl', 'wb') as f:\n",
    "    pickle.dump(transition_table, f, protocol=pickle.DEFAULT_PROTOCOL)\n",
    "\n",
    "with open(save_path + 'segments_dict.pkl', 'wb') as f:\n",
    "    pickle.dump(segments_dict, f, protocol=pickle.DEFAULT_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(save_path + 'transition_table.pkl','rb') as f:\n",
    "    transition_table = pickle.load(f)\n",
    "\n",
    "with open(save_path + 'segments_dict.pkl','rb') as f:\n",
    "    segments_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Start', 'wall', 'wall', 'wall', 'floor', 'inside wall', 'inside wall', 'floor', 'wall', 'wall', 'wall', 'wall', 'wall', 'wall', 'wall', 'wall', 'wall', 'wall', 'floor', 'floor', 'wall', 'wall', 'wall', 'roof', 'roof', 'roof', 'roof', 'Done']\n",
      "28\n",
      "(16, 16, 16)\n",
      "(26, 7)\n"
     ]
    }
   ],
   "source": [
    "DIM = 16\n",
    "down = ['floor', 'base', 'bottom', 'ground', 'foundation']\n",
    "up = ['roof', 'top', 'layer', 'ceiling', 'ledge', 'overhang', 'platform']\n",
    "\n",
    "# create ids for segment\n",
    "label_ids = {k: i for i, k in enumerate(segments_dict.keys())}\n",
    "\n",
    "def get_y_indeces(structure, x, z, segment, name):\n",
    "    s0, s1, s2 = segment.shape\n",
    "\n",
    "    for word in down:\n",
    "        # floor types go to the bottom\n",
    "        if name.find(word) != -1:\n",
    "            return 0, s1\n",
    "\n",
    "    for word in up:\n",
    "        # roof types go to the top\n",
    "        if name.find(word) != -1:\n",
    "            # roofs must not float\n",
    "            # find highest point in designated area\n",
    "            non_zero_ids = np.nonzero(\n",
    "                # slice the requested area\n",
    "                structure[x:x+s0, 0:DIM, z:z+s2])\n",
    "            # use the highest non-zero y index\n",
    "            if len(non_zero_ids[1]) == 0:\n",
    "                # roof part falls to the ground\n",
    "                return 1, 1+s1\n",
    "            # prevent building from clipping OOB vertically\n",
    "            h = non_zero_ids[1].max()\n",
    "            safety_clip = h + s1 - DIM if h + s1 >= DIM else 0\n",
    "            return (h - safety_clip, h + s1 - safety_clip)\n",
    "\n",
    "    # wall types stand upright on the floor\n",
    "    return 1, 1+s1\n",
    "\n",
    "def generate_structure(annotation, segments_dict):\n",
    "    structure = np.zeros(shape=(DIM,DIM,DIM), dtype=np.uint8)\n",
    "    # start building from the outer thirds inward\n",
    "    outer_thirds = [i for i in range(int(DIM/3))] + [i for i in range(int(2*DIM/3), DIM)]\n",
    "    [x, z] = choices(outer_thirds, k=2)\n",
    "    y = 0 # vertical dim in minetest\n",
    "\n",
    "    # in the outer thirds of the space we invert horizontal directions\n",
    "    turn_positive_zone = list(range(int(DIM/3)))\n",
    "    turn_negative_zone = [2 * int(DIM/3) + i for i in range(int(DIM/3))]\n",
    "    x_dir = 1 if x in turn_positive_zone else -1\n",
    "    z_dir = 1 if z in turn_positive_zone else -1\n",
    "\n",
    "    sequence = []\n",
    "\n",
    "    for segment_index, segment_label in enumerate(annotation):\n",
    "        if segment_index == 0:\n",
    "            continue\n",
    "        if segment_label == \"Done\":\n",
    "            break\n",
    "        choice, segment_uid = choices(segments_dict[segment_label])[0]\n",
    "        # prevent alteration of the segment dict\n",
    "        segment = np.copy(choice)\n",
    "        segment[segment == 1] = segment_index\n",
    "        s0, s1, s2 = segment.shape\n",
    "\n",
    "        x_dir = 1 if x in turn_positive_zone else x_dir\n",
    "        z_dir = 1 if z in turn_positive_zone else z_dir\n",
    "        x_dir = -1 if x in turn_negative_zone else x_dir\n",
    "        z_dir = -1 if z in turn_negative_zone else z_dir\n",
    "        # some safety constraints\n",
    "        x_dir *= -1 if x+x_dir*s0 >= DIM or x+x_dir*s0 < 0 else 1\n",
    "        z_dir *= -1 if z+z_dir*s2 >= DIM or z+z_dir*s2 < 0 else 1\n",
    "        next_x = x+x_dir*s0\n",
    "        next_z = z+z_dir*s2\n",
    "        \n",
    "        # update vertical position according to segment type\n",
    "        y, next_y = get_y_indeces(structure, x, z, segment, segment_label)\n",
    "        assert(y < next_y)\n",
    "        \n",
    "        # clip segments which do not fit in either direction\n",
    "        diff = [0, 0, 0]\n",
    "        for i, s in enumerate(structure[x:next_x:x_dir, y:next_y, z:next_z:z_dir].shape):\n",
    "            diff[i] = s - segment.shape[i]\n",
    "        if diff != [0, 0, 0]:\n",
    "            segment = segment[0:s0+diff[0], 0:s1+diff[1], 0:s2+diff[2]]\n",
    "        \n",
    "        segment_encoding = [\n",
    "            label_ids[segment_label],\n",
    "            min(x, next_x), max(x, next_x),\n",
    "            min(y, next_y), max(y, next_y), # just for safety, we never actually build downwards\n",
    "            min(z, next_z), max(z, next_z)\n",
    "            ]\n",
    "        sequence.append(segment_encoding)\n",
    "\n",
    "        try:\n",
    "            structure[x:next_x:x_dir, y:next_y, z:next_z:z_dir] = segment\n",
    "        except Exception as e:\n",
    "            print('space:', structure[x:next_x:x_dir, y:next_y, z:next_z:z_dir].shape)\n",
    "            print('segment:', segment.shape)\n",
    "            print('diff:', diff)\n",
    "\n",
    "        # build along the same axis\n",
    "        if s0 > s2:\n",
    "            x = next_x\n",
    "        else:\n",
    "            z = next_z\n",
    "    \n",
    "    # position the structure randomly to make it more easily\n",
    "    # distinguishable from noise than dense structures\n",
    "    # padded_structure = np.zeros((24, 24, 24), dtype=np.uint8)\n",
    "    # [rx, rz] = choices(list(range(6)), k=2)\n",
    "    # padded_structure[rx:rx+DIM, 0:+DIM, rz:rz+DIM] = structure\n",
    "    return structure, np.asarray(sequence, dtype=np.int16)\n",
    "\n",
    "# testing that everything works as expected\n",
    "markov_annotation = generate_annotation(transition_table, 20)\n",
    "print(markov_annotation)\n",
    "print(len(markov_annotation))\n",
    "artificial_structure, sequence = generate_structure(markov_annotation, segments_dict)\n",
    "print(artificial_structure.shape)\n",
    "print(sequence.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [02:40<00:00, 623.00it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "segmentation_only = []\n",
    "segmentation_and_sequence = []\n",
    "for i in tqdm(range(100000)):\n",
    "    annotation = generate_annotation(transition_table)\n",
    "    structure, sequence = generate_structure(annotation, segments_dict)\n",
    "    segmentation_only.append(structure)\n",
    "    segmentation_and_sequence.append((structure, sequence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "uint8\n",
      "(16, 16, 16)\n",
      "int16\n",
      "(9, 7)\n"
     ]
    }
   ],
   "source": [
    "# check that everything looks good\n",
    "print(len(segmentation_and_sequence))\n",
    "print(segmentation_and_sequence[0][0].dtype)\n",
    "print(segmentation_and_sequence[0][0].shape)\n",
    "print(segmentation_and_sequence[0][1].dtype)\n",
    "print(segmentation_and_sequence[0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100000, 16, 16, 16])\n",
      "torch.float32\n",
      "tensor(0.)\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "segmentation_only = np.asarray(segmentation_only, dtype=np.float32) / 32.0\n",
    "segmentation_only = torch.from_numpy(segmentation_only)\n",
    "\n",
    "# check that everything looks good\n",
    "print(segmentation_only.size())\n",
    "print(segmentation_only.dtype)\n",
    "print(segmentation_only.min())\n",
    "print(segmentation_only.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(save_path + 'segmentation_only.pkl', 'wb') as f:\n",
    "    pickle.dump(segmentation_only, f, protocol=pickle.DEFAULT_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(save_path + 'segmentation_and_sequence.pkl', 'wb') as f:\n",
    "    pickle.dump(segmentation_and_sequence, f, protocol=pickle.DEFAULT_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
